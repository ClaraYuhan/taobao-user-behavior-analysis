import pandas as pd
import mysql.connector
from tqdm import tqdm
import traceback
import time

# âœ… è®¾ç½® CSV è·¯å¾„
csv_file = '/Users/wuzeyu/qi/data_analysis_projects/project_1_taobao_behavior/data/raw/raw_user_behavior.csv'

# âœ… æ•°æ®åº“è¿æ¥é…ç½®
db_config = {
    'host': 'localhost',
    'user': 'root',
    'password': '123456',
    'database': 'taobao_behavior',
    'auth_plugin': 'mysql_native_password'
}

# âœ… è¡¨ä¿¡æ¯
table_name = 'taobao_behavior'
columns = ['user_id', 'item_id', 'category_id', 'behavior_type', 'ts']
start_row = 0
batch_size = 10000

# âœ… è®°å½•å¼€å§‹æ—¶é—´
start_time = time.time()

try:
    # âœ… è®¡ç®—æ€»è¡Œæ•°ï¼ˆç”¨äº tqdm è¿›åº¦æ¡ï¼‰
    with open(csv_file, 'r') as f:
        total_rows = sum(1 for _ in f)

    # âœ… å»ºç«‹æ•°æ®åº“è¿æ¥
    conn = mysql.connector.connect(**db_config)
    cursor = conn.cursor()

    # âœ… SQL æ’å…¥è¯­å¥
    sql = f"""
        INSERT INTO {table_name} ({', '.join(columns)})
        VALUES ({', '.join(['%s'] * len(columns))})
    """

    # âœ… åˆ†æ‰¹è¯»å–å¹¶å¯¼å…¥æ•°æ®
    reader = pd.read_csv(
        csv_file,
        header=None,
        names=columns,
        chunksize=batch_size,
        skiprows=range(1, start_row + 1)
    )

    print("ğŸ“¦ å¼€å§‹å¯¼å…¥æ•°æ®ä¸­ï¼Œè¯·ç¨å€™...")
    for i, chunk in enumerate(tqdm(reader, total=(total_rows - start_row) // batch_size)):
        data = chunk.values.tolist()
        cursor.executemany(sql, data)
        conn.commit()

    print(f"âœ… æ•°æ®å¯¼å…¥å®Œæˆï¼æ€»è€—æ—¶ {(time.time() - start_time)/60:.2f} åˆ†é’Ÿ")

except Exception as e:
    print("âŒ å‡ºç°é”™è¯¯ï¼š", e)
    traceback.print_exc()

finally:
    # âœ… å…³é—­è¿æ¥
    if 'cursor' in locals():
        cursor.close()
    if 'conn' in locals() and conn.is_connected():
        conn.close()
